{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahdishafiei/Brain-Tomur-Semantic-segmentation/blob/main/BCE%20and%20Focal%20loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXNKkw6H1igG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.metrics as metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daFmd4kF_W2H",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2rLtDDd1iic"
      },
      "outputs": [],
      "source": [
        "path = '/content/gdrive/MyDrive/data/'\n",
        "image_path = os.path.join(path, './crossimage/')\n",
        "mask_path = os.path.join(path, './crossmask/')\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "image_list = [image_path+i for i in image_list]\n",
        "image_list.sort()\n",
        "mask_list = [mask_path+i for i in mask_list]\n",
        "mask_list.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD6dmZZT1ilF"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 800\n",
        "IMG_HEIGHT = 512\n",
        "IMG_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Msx0EOe1lpt"
      },
      "outputs": [],
      "source": [
        "X_train = np.zeros((314, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((314, IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqfglYAZ1lsF"
      },
      "outputs": [],
      "source": [
        "Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWL96XuZ1luV"
      },
      "outputs": [],
      "source": [
        "print('Resizing training images ')\n",
        "n=0\n",
        "for i in image_list:\n",
        "    img = imread(i)[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img  #Fill empty X_train with values from img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGu1fbeh1lyO"
      },
      "outputs": [],
      "source": [
        "print('Resizing masks.. ')\n",
        "n=0\n",
        "for i in mask_list:\n",
        "    img = imread(i)\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH,1), mode='constant', preserve_range=True)\n",
        "    Y_train[n] = img  #Fill empty X_train with values from img\n",
        "    n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L54c22JJ1qnV"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.squeeze(Y_train[120,:,:,:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRevFr_oAH9_"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[120,:,:,:]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlhwYWTa1749"
      },
      "outputs": [],
      "source": [
        "pip install focal-loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P0KOlTIAbVX"
      },
      "outputs": [],
      "source": [
        "from focal_loss import BinaryFocalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrbf4xxD1vg_"
      },
      "source": [
        "### **U-Net Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnm02b0n1qpt"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "#Expansive path\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss=BinaryFocalLoss(gamma=2), metrics=[metrics.Precision(),'accuracy'])\n",
        "model.summary()\n",
        "\n",
        "################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sus3uWTR1qvN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow.keras.metrics as met"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzoDeAhsjLzD"
      },
      "outputs": [],
      "source": [
        "# Hausdorff distance\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "# Assuming you have two four-dimensional tensors representing the ground truth and predicted segmentation masks\n",
        "# Shape: (batch_size, height, width, num_classes)\n",
        "def Hausdorff(ground_truth_masks,predicted_masks):\n",
        "\n",
        "  # Convert the tensors to pixel coordinates\n",
        "  ground_truth_coords = []\n",
        "  predicted_coords = []\n",
        "\n",
        "  for batch in range(ground_truth_masks.shape[0]):\n",
        "      ground_truth_mask = ground_truth_masks[batch]\n",
        "      predicted_mask = predicted_masks[batch]\n",
        "\n",
        "      # Get the coordinates for each class in the ground truth mask\n",
        "      for class_idx in range(ground_truth_mask.shape[-1]):\n",
        "          coords = np.transpose(np.nonzero(ground_truth_mask[:, :, class_idx]))\n",
        "          ground_truth_coords.append(coords)\n",
        "\n",
        "      # Get the coordinates for each class in the predicted mask\n",
        "      for class_idx in range(predicted_mask.shape[-1]):\n",
        "          coords = np.transpose(np.nonzero(predicted_mask[:, :, class_idx]))\n",
        "          predicted_coords.append(coords)\n",
        "\n",
        "  # Concatenate the coordinates for all classes and batches\n",
        "  ground_truth_coords = np.concatenate(ground_truth_coords, axis=0)\n",
        "  predicted_coords = np.concatenate(predicted_coords, axis=0)\n",
        "\n",
        "  # Calculate the Hausdorff distance\n",
        "  hausdorff_distance = max(directed_hausdorff(ground_truth_coords, predicted_coords)[0],\n",
        "                          directed_hausdorff(predicted_coords, ground_truth_coords)[0])\n",
        "\n",
        "  return hausdorff_distance\n",
        "\n",
        "\n",
        "#Surface Dice\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def surface_dice_coefficient(ground_truth, predicted):\n",
        "    intersection = np.sum(ground_truth * predicted)\n",
        "    ground_truth_sum = np.sum(ground_truth)\n",
        "    predicted_sum = np.sum(predicted)\n",
        "\n",
        "    dice_coefficient = (2 * intersection) / (ground_truth_sum + predicted_sum)\n",
        "\n",
        "    return dice_coefficient\n",
        "\n",
        "# Assuming you have two four-dimensional tensors representing the ground truth and predicted segmentation masks\n",
        "# Shape: (batch_size, height, width, num_classes)\n",
        "def surface(ground_truth_masks,predicted_masks):\n",
        "\n",
        "  # Calculate the Surface Dice coefficient for each sample in the batch\n",
        "  batch_size = ground_truth_masks.shape[0]\n",
        "  surface_dice_coefficients = []\n",
        "\n",
        "  for i in range(batch_size-1):\n",
        "      ground_truth_mask = ground_truth_masks[i]\n",
        "      predicted_mask = predicted_masks[i]\n",
        "\n",
        "      surface_dice = surface_dice_coefficient(ground_truth_mask, predicted_mask)\n",
        "      surface_dice_coefficients.append(surface_dice)\n",
        "\n",
        "  # Calculate the average Surface Dice coefficient across the batch\n",
        "  average_surface_dice = np.mean(surface_dice_coefficients)\n",
        "  return average_surface_dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT8qcYPu3Zmm"
      },
      "outputs": [],
      "source": [
        "scores_CNN={\"accuracy\":[],\"precision\":[],\"recall\":[],\"f1\":[],\"confusion_matrix\":[],\"Hausdorff\":[],\"Surface\":[]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAuvzm1DMssT"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss=BinaryFocalLoss(gamma=2), metrics=[met.Precision(),'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQHDmzXiUZhh"
      },
      "outputs": [],
      "source": [
        "tf.keras.metrics.Precision(\n",
        "    thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYWeY77BXgMk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY7GOumIaE81"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/gdrive/MyDrive/scores_CNN.pkl', 'rb') as handle:\n",
        "    scores_CNN = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_CNN"
      ],
      "metadata": {
        "id": "0E9ZxRbge83G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0SUPmiA3Zo3"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=10)\n",
        "history = list()\n",
        "for train, test in kfold.split(X_train,y= [0] * 314):\n",
        "\tY_tr = Y_train[train]\n",
        "\tY_te = Y_train[test]\n",
        "\tX_tr = X_train[train]\n",
        "\tX_te = X_train[test]\n",
        "\tmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "\tmodel.compile(optimizer='adam', loss=BinaryFocalLoss(gamma=2), metrics=[met.Precision(),'accuracy'])\n",
        "\tresult = model.fit(X_tr, Y_tr,\n",
        "                    batch_size = 16,\n",
        "                    verbose=1,\n",
        "                    epochs=10,\n",
        "                    shuffle=False)\n",
        "\n",
        "\n",
        "\tprint(\"Next Model ------------------------------------------------------------------------------------------------\")\n",
        "\t# evaluate the model\n",
        "\ttrain_predict = model.predict(X_te, verbose=1)\n",
        "\tpreds_train_t = (train_predict > 0.5).astype(int)\n",
        "\tscores_CNN[\"accuracy\"].append(model.evaluate(X_te, Y_te, verbose=1)[2]*100)\n",
        "\tscores_CNN[\"confusion_matrix\"].append(metrics.confusion_matrix(Y_te.reshape(-1).astype(int), preds_train_t.reshape(-1)))\n",
        "\tscores_CNN[\"recall\"].append(metrics.recall_score(Y_te.reshape(-1).astype(int),preds_train_t.reshape(-1)))\n",
        "\tscores_CNN[\"precision\"].append(metrics.precision_score(Y_te.reshape(-1).astype(int),preds_train_t.reshape(-1)))\n",
        "\tscores_CNN[\"f1\"].append(metrics.f1_score(Y_te.reshape(-1).astype(int), preds_train_t.reshape(-1)))\n",
        "\tscores_CNN[\"Hausdorff\"].append(Hausdorff(Y_te,train_predict))\n",
        "\tscores_CNN[\"Surface\"].append(surface(Y_te.astype(int),train_predict.astype(int)))\n",
        "\twith open('/content/gdrive/MyDrive/scores_CNN.pkl', 'wb') as fp:\n",
        "\t\tpickle.dump(scores_CNN, fp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_CNN"
      ],
      "metadata": {
        "id": "VFNIa38ix4Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTjJ8S2GnFda"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/gdrive/MyDrive/scores_CNN.pkl', 'wb') as fp:\n",
        "    pickle.dump(scores_CNN, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ORSXHcs3ZrF"
      },
      "outputs": [],
      "source": [
        "scores_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG3PXlaVmCRy"
      },
      "outputs": [],
      "source": [
        "j= 44\n",
        "plt.imshow(X_train[j,:,:,:]);\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(Y_train[j,:,:,:]))\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(preds_train_t[j,:,:,:]))\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(train_predict[j,:,:,:]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz2E89PM3ZtF"
      },
      "outputs": [],
      "source": [
        "i = 0 # from zero to (number of fold) -1\n",
        "# summarize history for accuracy\n",
        "plt.plot(history[i].history['accuracy'])\n",
        "plt.plot(history[i].history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history[i].history['loss'])\n",
        "plt.plot(history[i].history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}